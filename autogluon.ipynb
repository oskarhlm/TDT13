{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329d8dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset\n",
    "from lib.autogluon import MultilabelPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f117bbb5",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Let's now apply our multi-label predictor to predict multiple columns in a data table. We first train models to predict each of the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ea2dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv')\n",
    "subsample_size = 500  # subsample subset of data for faster demo, try setting this to much larger values\n",
    "train_data = train_data.sample(n=subsample_size, random_state=0)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9192e870",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['education-num','education','class']  # which columns to predict based on the others\n",
    "problem_types = ['regression','multiclass','binary']  # type of each prediction problem (optional)\n",
    "eval_metrics = ['mean_absolute_error','accuracy','accuracy']  # metrics used to evaluate predictions for each label (optional)\n",
    "save_path = 'agModels-predictEducationClass'  # specifies folder to store trained models (optional)\n",
    "\n",
    "time_limit = 5  # how many seconds to train the TabularPredictor for each label, set much larger in your applications!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9968b70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_predictor = MultilabelPredictor(labels=labels, problem_types=problem_types, eval_metrics=eval_metrics, path=save_path)\n",
    "multi_predictor.fit(train_data, time_limit=time_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b541c6",
   "metadata": {},
   "source": [
    "## Inference and Evaluation\n",
    "\n",
    "After training, you can easily use the `MultilabelPredictor` to predict all labels in new data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5f5d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv')\n",
    "test_data = test_data.sample(n=subsample_size, random_state=0)\n",
    "test_data_nolab = test_data.drop(columns=labels)  # unnecessary, just to demonstrate we're not cheating here\n",
    "test_data_nolab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ef3acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_predictor = MultilabelPredictor.load(save_path)  # unnecessary, just demonstrates how to load previously-trained multilabel predictor from file\n",
    "\n",
    "predictions = multi_predictor.predict(test_data_nolab)\n",
    "print(\"Predictions:  \\n\", predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a845bab",
   "metadata": {},
   "source": [
    "We can also easily evaluate the performance of our predictions if our new data contain the ground truth labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac52d82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations = multi_predictor.evaluate(test_data)\n",
    "print(evaluations)\n",
    "print(\"Evaluated using metrics:\", multi_predictor.eval_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f30569d",
   "metadata": {},
   "source": [
    "## Accessing the TabularPredictorÂ for One Label\n",
    "\n",
    "We can also directly work with the `TabularPredictor` for any one of the labels as follows. However we recommend you set `consider_labels_correlation=False` before training if you later plan to use an individual `TabularPredictor` to predict just one label rather than all of the labels predicted by the `MultilabelPredictor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e796708d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_class = multi_predictor.get_predictor('class')\n",
    "predictor_class.leaderboard(silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eac71ef",
   "metadata": {},
   "source": [
    "## Tips\n",
    "\n",
    "In order to obtain the best predictions, you should generally add the following arguments to `MultilabelPredictor.fit()`:\n",
    "\n",
    "1) Specify `eval_metrics` to the metrics you will use to evaluate predictions for each label\n",
    "\n",
    "2) Specify `presets='best_quality'` to tell AutoGluon you care about predictive performance more than latency/memory usage, which will utilize stack ensembling when predicting each label.\n",
    "\n",
    "\n",
    "If you find that too much memory/disk is being used, try calling `MultilabelPredictor.fit()` with additional arguments discussed under [\"If you encounter memory issues\" in the In Depth Tutorial](../tabular-indepth.ipynb) or [\"If you encounter disk space issues\"](../tabular-indepth.ipynb).\n",
    "\n",
    "If you find inference too slow, you can try the strategies discussed under [\"Accelerating Inference\" in the In Depth Tutorial](../tabular-indepth.ipynb).\n",
    "In particular, simply try specifying the following preset in `MultilabelPredictor.fit()`: `presets = ['good_quality', 'optimize_for_deployment']`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
