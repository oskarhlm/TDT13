\section{Discussion}
\label{sec:Discussion}

\begin{comment}
It is important to include a discussion, which describes what you have learned so far, the merits of the work as well as its limitations.
It can be a separate section or it can appear together with the results or be part of the conclusion).
When evaluating your results, avoid drawing grand conclusions, beyond those that your results can in fact support.
Further, although you may have designed your experiments to answer certain questions,
the results may raise other questions in the eyes of the reader.
It is important that you study the graphs/tables to look for unusual features/entries, and discuss these as well as the main findings.
In particular, carry out an error analysis: b went wrong and why?
\end{comment}

Results show that the Swiss LV95 map projection proved most efficient for predicting geolocation from Swiss Jodel messages. This may indicate that using a metric \gls{acr:crs} like LV95 over a spherical representation like latitude and longitude values can be beneficial in a double regression task for predicting geographical coordinates. It could seem that the model finds it harder to learn spherical representations. These findings are counter to those of \cite[5]{scherrerHeLjuVarDial20202020}, who found that raw latitude and longitude values do not perform worse than metric projections. They only did tests on the UTM projection, however, and did not use the LV95 projection.

Not surprisingly, the language-specific model (\texttt{bert-base-german-cased-finetuned-swiss}) proved most suitable for this task. Being pre-trained on large Swiss corpora, its creators were able to show a 5 percent improvement over its German parent model. It seems this pre-training enhances the model's ability to pick up on dialectal details in the data. The X-Mod-based \texttt{swissbert} model, which is based on a model designed to be multilingual \citep{pfeifferLiftingCurseMultilinguality2022}, did not seem to possess the same dialectal knowledge and performed only marginally better than the German \texttt{bert-base-german-uncased} model.

Furthermore, it is clear from the results that the learning rate schedulers used did not improve the test score. \texttt{ReduceLROnPlateau} and \texttt{OneCycleLR} were tested, and while they greatly reduced the convergence time, they were unable to achieve satisfactory median distances. Since the schedulers showed such little promise for this task, they were not investigated much further. I do think, however, that they could prove efficient if one can find a suitable set of initialization parameters.

Overall, the results are quite good and would suffice for a second place in the VarDial 2020 competition. One would expect, however, that with newer models like \texttt{bert-base-german-cased-finetuned-swiss}, one should be able to achieve better results while using methods similar to those used in 2020. This turned out not to be the case. Pinpointing an exact reason is difficult, but \cite{scherrerHeLjuVarDial20202020} having trained a total of 48 models as opposed to the 15 of this study could be one of them. There may also be some default hyperparameters in the \texttt{simpletransformers} library that \cite{scherrerHeLjuVarDial20202020} did not discuss in their that made it difficult to recreate their results, or there might be other totally different issues with the implementation in this project.
